{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVxGgMZzqNC3vhQ45fezX1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonLn0711/1131_TAICA_ML/blob/main/FP__stage_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install minisom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH5YWMks7v5M",
        "outputId": "bd227b93-b4dd-4df7-e33b-47e5c7cab420"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting minisom\n",
            "  Downloading MiniSom-2.3.3.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minisom\n",
            "  Building wheel for minisom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minisom: filename=MiniSom-2.3.3-py3-none-any.whl size=11706 sha256=3656e7961cdf75517c6d22d1cfa4c8a1e3392ae8d4f33279267cd41931b1b9c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/98/a5/52dee3e8ed1dbfc4d77e4da41b6d89dd7ab9ead1b921e766f8\n",
            "Successfully built minisom\n",
            "Installing collected packages: minisom\n",
            "Successfully installed minisom-2.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QtT5jS0kWZ0Y"
      },
      "outputs": [],
      "source": [
        "# Unsupervised Evaluation\n",
        "# Method 4: Self-Organizing Maps (SOM)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, zero_one_loss\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from minisom import MiniSom # Fix v4.1.2: Instead of importing 'somoclu', we use 'minisom' to handle Self-Organizing Maps (SOM) for fixing compatibility issues with mac OS due to missing linked libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Load data\n",
        "drive.mount('/d')\n",
        "file_path_1 = '/d/MyDrive/train_data.csv'\n",
        "file_path_2 = '/d/MyDrive/same_season_test_data.csv'\n",
        "\n",
        "train_data = pd.read_csv(file_path_1)\n",
        "test_data = pd.read_csv(file_path_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXwcaQYTzCg-",
        "outputId": "25606f55-8ccb-4f3b-9613-5e559380cc30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the target variable for test data using Self-Organizing Maps (SOM)\n",
        "# Select Relevant Features\n",
        "features = [\n",
        "    'home_team_wins_mean',\n",
        "    'away_team_wins_mean',\n",
        "    'home_batting_batting_avg_mean',\n",
        "    'away_batting_batting_avg_mean'\n",
        "]\n",
        "X = test_data[features].fillna(0)\n",
        "\n",
        "# Standardize Features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply SOM using MiniSom\n",
        "som = MiniSom(x=10, y=10, input_len=X_scaled.shape[1], sigma=1.0, learning_rate=0.5)\n",
        "som.random_weights_init(X_scaled)\n",
        "som.train_random(X_scaled, 100)  # Train for 100 iterations\n",
        "\n",
        "# Extract Cluster Assignments\n",
        "bmus = np.array([som.winner(x) for x in X_scaled])\n",
        "test_data['cluster'] = bmus[:, 0] * 10 + bmus[:, 1]\n",
        "\n",
        "# Assign Proxy Target Variable\n",
        "# Determine which cluster is more likely to be home wins\n",
        "cluster_home_win = test_data.groupby('cluster')['home_team_wins_mean'].mean().idxmax()\n",
        "test_data['home_team_win'] = (test_data['cluster'] == cluster_home_win).astype(int)"
      ],
      "metadata": {
        "id": "l2F5CyjE7utd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop date columns from the datasets\n",
        "train_data.drop(columns=['date'], inplace=True, errors='ignore')\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = ['home_team_abbr', 'away_team_abbr', 'home_pitcher', 'away_pitcher', 'home_team_season', 'away_team_season']\n",
        "numeric_cols = [col for col in train_data.columns if col not in categorical_cols + ['home_team_win']]\n",
        "\n",
        "# Creating pipelines for the preprocessing of numeric and categorical columns\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Column transformer for applying different preprocessing to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])"
      ],
      "metadata": {
        "id": "AyQtvT3z3FP4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split features and target\n",
        "X_train = train_data.drop(columns=['home_team_win'])\n",
        "y_train = train_data['home_team_win']\n",
        "X_test = test_data.drop(columns=['home_team_win'])\n",
        "y_test = test_data['home_team_win']\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "53Wrk7J84Ird"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Outlier Detection with Modified Threshold\n",
        "def christoffel_darboux_kernel_outliers(data, n_neighbors=5, threshold=7.0):\n",
        "    nn = NearestNeighbors(n_neighbors=n_neighbors).fit(data)\n",
        "    distances, _ = nn.kneighbors(data)\n",
        "    kernel_density_scores = np.mean(distances, axis=1)\n",
        "\n",
        "    outliers = np.where(kernel_density_scores > threshold)[0]\n",
        "    return outliers\n",
        "\n",
        "# Detect and remove outliers from training data\n",
        "outliers = christoffel_darboux_kernel_outliers(X_train_preprocessed)\n",
        "print(f\"Initial Outliers Detected: {len(outliers)}\")\n",
        "\n",
        "# Adjust outlier removal to prevent empty dataset\n",
        "if len(outliers) < X_train_preprocessed.shape[0] * 0.8:  # Keep at least 20% of the data\n",
        "    X_train_filtered = X_train_preprocessed[np.isin(range(len(X_train)), outliers, invert=True)]\n",
        "    y_train_filtered = y_train.drop(outliers).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"Too many outliers detected; skipping outlier removal.\")\n",
        "    X_train_filtered = X_train_preprocessed\n",
        "    y_train_filtered = y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnjWmcYb8KQg",
        "outputId": "1f8125ac-a395-4633-d40f-6321f1ff8e6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Outliers Detected: 7919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Feature Engineering with ARMA for Temporal Dependencies\n",
        "win_ratios = train_data.groupby('home_team_abbr')['home_team_win'].apply(list)\n",
        "forecasted_ratios = {}\n",
        "for team, ratios in win_ratios.items():\n",
        "    if len(ratios) > 5:\n",
        "        try:\n",
        "            model = ARIMA(ratios, order=(1, 0, 1))  # Simplified ARIMA model\n",
        "            arma_model = model.fit()\n",
        "            forecast = arma_model.forecast(steps=1)\n",
        "            forecasted_ratios[team] = forecast[0]\n",
        "        except Exception as e:\n",
        "            print(f\"ARIMA model failed for team {team}: {e}\")\n",
        "\n",
        "train_data['forecasted_win_ratio'] = train_data['home_team_abbr'].map(forecasted_ratios).fillna(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waAz_NN28Mno",
        "outputId": "2470b136-588d-459b-fe23-3dc7d64d2a71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-stationary starting autoregressive parameters'\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
            "  warn('Non-invertible starting MA parameters found.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Baseline Models - Logistic Regression and Decision Tree\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_filtered, y_train_filtered)\n",
        "logreg_pred = logreg.predict(X_test_preprocessed)\n",
        "print(\"Logistic Regression - Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train_filtered, y_train_filtered)\n",
        "dt_pred = dt.predict(X_test_preprocessed)\n",
        "print(\"Decision Tree - Accuracy:\", accuracy_score(y_test, dt_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmeZqXoN8OMw",
        "outputId": "4014f40b-4f73-40d2-d981-c80474ad987d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.49700889248181085\n",
            "Decision Tree - Accuracy: 0.48536782538399353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Custom Online Learning Model - Mondrian Forest Approximation with Incremental Updates\n",
        "forest = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "forest.fit(X_train_filtered, y_train_filtered)\n",
        "\n",
        "# Function to incrementally update the model\n",
        "def incremental_update(model, new_data, new_labels):\n",
        "    model.fit(new_data, new_labels)\n",
        "    return model\n",
        "\n",
        "# Initial evaluation\n",
        "forest_pred = forest.predict(X_test_preprocessed)\n",
        "print(\"Initial Mondrian Forest Approximation - Accuracy:\", accuracy_score(y_test, forest_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv0Ce-Bn8QAp",
        "outputId": "5e5b0430-50ca-4e81-cfa6-c382852beaf8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Mondrian Forest Approximation - Accuracy: 0.5219078415521423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Simulate Incremental Learning with Time-Based Data Batches\n",
        "batch_size = 50  # Define batch size for incremental updates\n",
        "num_batches = X_test_preprocessed.shape[0] // batch_size\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start = i * batch_size\n",
        "    end = (i + 1) * batch_size\n",
        "    X_batch = X_test_preprocessed[start:end]\n",
        "    y_batch = y_test.iloc[start:end]\n",
        "\n",
        "    # Evaluate before update\n",
        "    batch_pred = forest.predict(X_batch)\n",
        "    batch_accuracy = accuracy_score(y_batch, batch_pred)\n",
        "    print(f\"Batch {i+1} Accuracy before update: {batch_accuracy:.2f}\")\n",
        "\n",
        "    # Incremental update\n",
        "    forest = incremental_update(forest, X_batch, y_batch)\n",
        "\n",
        "    # Evaluate after update\n",
        "    batch_pred_updated = forest.predict(X_batch)\n",
        "    batch_accuracy_updated = accuracy_score(y_batch, batch_pred_updated)\n",
        "    print(f\"Batch {i+1} Accuracy after update: {batch_accuracy_updated:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtPHAxuS8RVQ",
        "outputId": "c7b29536-4fcd-4614-c8f3-d4aa7a1179ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 Accuracy before update: 0.50\n",
            "Batch 1 Accuracy after update: 0.98\n",
            "Batch 2 Accuracy before update: 1.00\n",
            "Batch 2 Accuracy after update: 1.00\n",
            "Batch 3 Accuracy before update: 1.00\n",
            "Batch 3 Accuracy after update: 1.00\n",
            "Batch 4 Accuracy before update: 0.96\n",
            "Batch 4 Accuracy after update: 0.98\n",
            "Batch 5 Accuracy before update: 1.00\n",
            "Batch 5 Accuracy after update: 1.00\n",
            "Batch 6 Accuracy before update: 1.00\n",
            "Batch 6 Accuracy after update: 1.00\n",
            "Batch 7 Accuracy before update: 1.00\n",
            "Batch 7 Accuracy after update: 1.00\n",
            "Batch 8 Accuracy before update: 1.00\n",
            "Batch 8 Accuracy after update: 1.00\n",
            "Batch 9 Accuracy before update: 1.00\n",
            "Batch 9 Accuracy after update: 1.00\n",
            "Batch 10 Accuracy before update: 0.94\n",
            "Batch 10 Accuracy after update: 1.00\n",
            "Batch 11 Accuracy before update: 1.00\n",
            "Batch 11 Accuracy after update: 1.00\n",
            "Batch 12 Accuracy before update: 1.00\n",
            "Batch 12 Accuracy after update: 1.00\n",
            "Batch 13 Accuracy before update: 1.00\n",
            "Batch 13 Accuracy after update: 1.00\n",
            "Batch 14 Accuracy before update: 1.00\n",
            "Batch 14 Accuracy after update: 1.00\n",
            "Batch 15 Accuracy before update: 1.00\n",
            "Batch 15 Accuracy after update: 1.00\n",
            "Batch 16 Accuracy before update: 0.98\n",
            "Batch 16 Accuracy after update: 1.00\n",
            "Batch 17 Accuracy before update: 0.98\n",
            "Batch 17 Accuracy after update: 1.00\n",
            "Batch 18 Accuracy before update: 1.00\n",
            "Batch 18 Accuracy after update: 1.00\n",
            "Batch 19 Accuracy before update: 1.00\n",
            "Batch 19 Accuracy after update: 1.00\n",
            "Batch 20 Accuracy before update: 1.00\n",
            "Batch 20 Accuracy after update: 1.00\n",
            "Batch 21 Accuracy before update: 1.00\n",
            "Batch 21 Accuracy after update: 1.00\n",
            "Batch 22 Accuracy before update: 1.00\n",
            "Batch 22 Accuracy after update: 1.00\n",
            "Batch 23 Accuracy before update: 1.00\n",
            "Batch 23 Accuracy after update: 1.00\n",
            "Batch 24 Accuracy before update: 0.98\n",
            "Batch 24 Accuracy after update: 1.00\n",
            "Batch 25 Accuracy before update: 1.00\n",
            "Batch 25 Accuracy after update: 1.00\n",
            "Batch 26 Accuracy before update: 1.00\n",
            "Batch 26 Accuracy after update: 1.00\n",
            "Batch 27 Accuracy before update: 0.98\n",
            "Batch 27 Accuracy after update: 1.00\n",
            "Batch 28 Accuracy before update: 1.00\n",
            "Batch 28 Accuracy after update: 1.00\n",
            "Batch 29 Accuracy before update: 0.96\n",
            "Batch 29 Accuracy after update: 0.98\n",
            "Batch 30 Accuracy before update: 1.00\n",
            "Batch 30 Accuracy after update: 1.00\n",
            "Batch 31 Accuracy before update: 0.98\n",
            "Batch 31 Accuracy after update: 1.00\n",
            "Batch 32 Accuracy before update: 1.00\n",
            "Batch 32 Accuracy after update: 1.00\n",
            "Batch 33 Accuracy before update: 1.00\n",
            "Batch 33 Accuracy after update: 1.00\n",
            "Batch 34 Accuracy before update: 1.00\n",
            "Batch 34 Accuracy after update: 1.00\n",
            "Batch 35 Accuracy before update: 1.00\n",
            "Batch 35 Accuracy after update: 1.00\n",
            "Batch 36 Accuracy before update: 1.00\n",
            "Batch 36 Accuracy after update: 1.00\n",
            "Batch 37 Accuracy before update: 1.00\n",
            "Batch 37 Accuracy after update: 1.00\n",
            "Batch 38 Accuracy before update: 0.98\n",
            "Batch 38 Accuracy after update: 0.98\n",
            "Batch 39 Accuracy before update: 1.00\n",
            "Batch 39 Accuracy after update: 1.00\n",
            "Batch 40 Accuracy before update: 0.98\n",
            "Batch 40 Accuracy after update: 1.00\n",
            "Batch 41 Accuracy before update: 1.00\n",
            "Batch 41 Accuracy after update: 1.00\n",
            "Batch 42 Accuracy before update: 1.00\n",
            "Batch 42 Accuracy after update: 1.00\n",
            "Batch 43 Accuracy before update: 1.00\n",
            "Batch 43 Accuracy after update: 1.00\n",
            "Batch 44 Accuracy before update: 1.00\n",
            "Batch 44 Accuracy after update: 1.00\n",
            "Batch 45 Accuracy before update: 1.00\n",
            "Batch 45 Accuracy after update: 1.00\n",
            "Batch 46 Accuracy before update: 0.98\n",
            "Batch 46 Accuracy after update: 1.00\n",
            "Batch 47 Accuracy before update: 1.00\n",
            "Batch 47 Accuracy after update: 1.00\n",
            "Batch 48 Accuracy before update: 1.00\n",
            "Batch 48 Accuracy after update: 1.00\n",
            "Batch 49 Accuracy before update: 0.98\n",
            "Batch 49 Accuracy after update: 0.98\n",
            "Batch 50 Accuracy before update: 0.98\n",
            "Batch 50 Accuracy after update: 1.00\n",
            "Batch 51 Accuracy before update: 1.00\n",
            "Batch 51 Accuracy after update: 1.00\n",
            "Batch 52 Accuracy before update: 1.00\n",
            "Batch 52 Accuracy after update: 1.00\n",
            "Batch 53 Accuracy before update: 1.00\n",
            "Batch 53 Accuracy after update: 1.00\n",
            "Batch 54 Accuracy before update: 1.00\n",
            "Batch 54 Accuracy after update: 1.00\n",
            "Batch 55 Accuracy before update: 0.98\n",
            "Batch 55 Accuracy after update: 1.00\n",
            "Batch 56 Accuracy before update: 0.98\n",
            "Batch 56 Accuracy after update: 1.00\n",
            "Batch 57 Accuracy before update: 1.00\n",
            "Batch 57 Accuracy after update: 1.00\n",
            "Batch 58 Accuracy before update: 1.00\n",
            "Batch 58 Accuracy after update: 1.00\n",
            "Batch 59 Accuracy before update: 1.00\n",
            "Batch 59 Accuracy after update: 1.00\n",
            "Batch 60 Accuracy before update: 0.98\n",
            "Batch 60 Accuracy after update: 0.98\n",
            "Batch 61 Accuracy before update: 0.98\n",
            "Batch 61 Accuracy after update: 1.00\n",
            "Batch 62 Accuracy before update: 1.00\n",
            "Batch 62 Accuracy after update: 1.00\n",
            "Batch 63 Accuracy before update: 0.98\n",
            "Batch 63 Accuracy after update: 1.00\n",
            "Batch 64 Accuracy before update: 1.00\n",
            "Batch 64 Accuracy after update: 1.00\n",
            "Batch 65 Accuracy before update: 1.00\n",
            "Batch 65 Accuracy after update: 1.00\n",
            "Batch 66 Accuracy before update: 0.96\n",
            "Batch 66 Accuracy after update: 0.98\n",
            "Batch 67 Accuracy before update: 0.98\n",
            "Batch 67 Accuracy after update: 1.00\n",
            "Batch 68 Accuracy before update: 0.96\n",
            "Batch 68 Accuracy after update: 0.98\n",
            "Batch 69 Accuracy before update: 1.00\n",
            "Batch 69 Accuracy after update: 1.00\n",
            "Batch 70 Accuracy before update: 1.00\n",
            "Batch 70 Accuracy after update: 1.00\n",
            "Batch 71 Accuracy before update: 1.00\n",
            "Batch 71 Accuracy after update: 1.00\n",
            "Batch 72 Accuracy before update: 0.96\n",
            "Batch 72 Accuracy after update: 1.00\n",
            "Batch 73 Accuracy before update: 1.00\n",
            "Batch 73 Accuracy after update: 1.00\n",
            "Batch 74 Accuracy before update: 1.00\n",
            "Batch 74 Accuracy after update: 1.00\n",
            "Batch 75 Accuracy before update: 1.00\n",
            "Batch 75 Accuracy after update: 1.00\n",
            "Batch 76 Accuracy before update: 1.00\n",
            "Batch 76 Accuracy after update: 1.00\n",
            "Batch 77 Accuracy before update: 0.98\n",
            "Batch 77 Accuracy after update: 1.00\n",
            "Batch 78 Accuracy before update: 1.00\n",
            "Batch 78 Accuracy after update: 1.00\n",
            "Batch 79 Accuracy before update: 0.98\n",
            "Batch 79 Accuracy after update: 1.00\n",
            "Batch 80 Accuracy before update: 1.00\n",
            "Batch 80 Accuracy after update: 1.00\n",
            "Batch 81 Accuracy before update: 1.00\n",
            "Batch 81 Accuracy after update: 1.00\n",
            "Batch 82 Accuracy before update: 1.00\n",
            "Batch 82 Accuracy after update: 1.00\n",
            "Batch 83 Accuracy before update: 1.00\n",
            "Batch 83 Accuracy after update: 1.00\n",
            "Batch 84 Accuracy before update: 1.00\n",
            "Batch 84 Accuracy after update: 1.00\n",
            "Batch 85 Accuracy before update: 1.00\n",
            "Batch 85 Accuracy after update: 1.00\n",
            "Batch 86 Accuracy before update: 0.98\n",
            "Batch 86 Accuracy after update: 1.00\n",
            "Batch 87 Accuracy before update: 1.00\n",
            "Batch 87 Accuracy after update: 1.00\n",
            "Batch 88 Accuracy before update: 1.00\n",
            "Batch 88 Accuracy after update: 1.00\n",
            "Batch 89 Accuracy before update: 0.98\n",
            "Batch 89 Accuracy after update: 1.00\n",
            "Batch 90 Accuracy before update: 1.00\n",
            "Batch 90 Accuracy after update: 1.00\n",
            "Batch 91 Accuracy before update: 0.98\n",
            "Batch 91 Accuracy after update: 1.00\n",
            "Batch 92 Accuracy before update: 1.00\n",
            "Batch 92 Accuracy after update: 1.00\n",
            "Batch 93 Accuracy before update: 1.00\n",
            "Batch 93 Accuracy after update: 1.00\n",
            "Batch 94 Accuracy before update: 1.00\n",
            "Batch 94 Accuracy after update: 1.00\n",
            "Batch 95 Accuracy before update: 0.98\n",
            "Batch 95 Accuracy after update: 1.00\n",
            "Batch 96 Accuracy before update: 1.00\n",
            "Batch 96 Accuracy after update: 1.00\n",
            "Batch 97 Accuracy before update: 1.00\n",
            "Batch 97 Accuracy after update: 1.00\n",
            "Batch 98 Accuracy before update: 0.98\n",
            "Batch 98 Accuracy after update: 1.00\n",
            "Batch 99 Accuracy before update: 1.00\n",
            "Batch 99 Accuracy after update: 1.00\n",
            "Batch 100 Accuracy before update: 1.00\n",
            "Batch 100 Accuracy after update: 1.00\n",
            "Batch 101 Accuracy before update: 0.96\n",
            "Batch 101 Accuracy after update: 0.98\n",
            "Batch 102 Accuracy before update: 1.00\n",
            "Batch 102 Accuracy after update: 1.00\n",
            "Batch 103 Accuracy before update: 1.00\n",
            "Batch 103 Accuracy after update: 1.00\n",
            "Batch 104 Accuracy before update: 1.00\n",
            "Batch 104 Accuracy after update: 1.00\n",
            "Batch 105 Accuracy before update: 1.00\n",
            "Batch 105 Accuracy after update: 1.00\n",
            "Batch 106 Accuracy before update: 0.98\n",
            "Batch 106 Accuracy after update: 0.98\n",
            "Batch 107 Accuracy before update: 0.98\n",
            "Batch 107 Accuracy after update: 0.98\n",
            "Batch 108 Accuracy before update: 1.00\n",
            "Batch 108 Accuracy after update: 1.00\n",
            "Batch 109 Accuracy before update: 1.00\n",
            "Batch 109 Accuracy after update: 1.00\n",
            "Batch 110 Accuracy before update: 1.00\n",
            "Batch 110 Accuracy after update: 1.00\n",
            "Batch 111 Accuracy before update: 0.98\n",
            "Batch 111 Accuracy after update: 1.00\n",
            "Batch 112 Accuracy before update: 0.96\n",
            "Batch 112 Accuracy after update: 1.00\n",
            "Batch 113 Accuracy before update: 1.00\n",
            "Batch 113 Accuracy after update: 1.00\n",
            "Batch 114 Accuracy before update: 1.00\n",
            "Batch 114 Accuracy after update: 1.00\n",
            "Batch 115 Accuracy before update: 1.00\n",
            "Batch 115 Accuracy after update: 1.00\n",
            "Batch 116 Accuracy before update: 1.00\n",
            "Batch 116 Accuracy after update: 1.00\n",
            "Batch 117 Accuracy before update: 1.00\n",
            "Batch 117 Accuracy after update: 1.00\n",
            "Batch 118 Accuracy before update: 1.00\n",
            "Batch 118 Accuracy after update: 1.00\n",
            "Batch 119 Accuracy before update: 1.00\n",
            "Batch 119 Accuracy after update: 1.00\n",
            "Batch 120 Accuracy before update: 1.00\n",
            "Batch 120 Accuracy after update: 1.00\n",
            "Batch 121 Accuracy before update: 0.98\n",
            "Batch 121 Accuracy after update: 1.00\n",
            "Batch 122 Accuracy before update: 1.00\n",
            "Batch 122 Accuracy after update: 1.00\n",
            "Batch 123 Accuracy before update: 1.00\n",
            "Batch 123 Accuracy after update: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Model Evaluation - Accuracy and 0/1 Error\n",
        "models = {\n",
        "    \"Logistic Regression\": logreg,\n",
        "    \"Decision Tree\": dt,\n",
        "    \"Mondrian Forest Approximation\": forest\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    y_pred = model.predict(X_test_preprocessed)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    error = zero_one_loss(y_test, y_pred)\n",
        "    print(f\"{model_name} - Accuracy: {accuracy:.2f}, 0/1 Error: {error:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL_Ij_yn8TWZ",
        "outputId": "b5805c75-0212-4fb0-a195-497a59bb342e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.50, 0/1 Error: 0.50\n",
            "Decision Tree - Accuracy: 0.49, 0/1 Error: 0.51\n",
            "Mondrian Forest Approximation - Accuracy: 0.99, 0/1 Error: 0.01\n"
          ]
        }
      ]
    }
  ]
}